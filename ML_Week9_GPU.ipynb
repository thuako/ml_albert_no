{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Softmax CIFAR-10: Using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10: Softmax (10-classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 1: Load the entire CIFAR-10 dataset\n",
    "'''\n",
    "\n",
    "train_CIFAR = datasets.CIFAR10(root='./cifar_10data/',\n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_CIFAR = datasets.CIFAR10(root='./cifar_10data/',\n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "Step 2: Since there are 10 classes, the output should be 10\n",
    "'''\n",
    "class softmax(nn.Module) :\n",
    "    '''\n",
    "    Initialize model\n",
    "        input_dim : dimension of given input data\n",
    "    '''\n",
    "    def __init__(self, input_dim=3*32*32) :\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, 10, bias=True)\n",
    "\n",
    "    ''' forward given input x '''\n",
    "    def forward(self, x) :\n",
    "        return self.linear(x.float().view(-1, 3*32*32))\n",
    "\n",
    "'''\n",
    "Step 3: Create the model, specify loss function and optimizer\n",
    "'''\n",
    "torch.cuda.empty_cache()\n",
    "device = \"cuda\"  # device = \"cpu\"\n",
    "model = softmax().to(device)                         # Define a Neural Network Model\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()     # Specify loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)   # specify SGD with learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, loss = 76.61995244026184\n",
      "Epoch: 2/10, loss = 75.97522270679474\n",
      "Epoch: 3/10, loss = 76.3399407863617\n",
      "Epoch: 4/10, loss = 74.82120096683502\n",
      "Epoch: 5/10, loss = 74.94836807250977\n",
      "Epoch: 6/10, loss = 74.76631128787994\n",
      "Epoch: 7/10, loss = 74.07092273235321\n",
      "Epoch: 8/10, loss = 73.19631540775299\n",
      "Epoch: 9/10, loss = 72.71592462062836\n",
      "Epoch: 10/10, loss = 71.78250026702881\n",
      "Time ellapsed in training is: 47.79119086265564\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 4: Train model with SGD\n",
    "'''\n",
    "train_loader = DataLoader(dataset=train_CIFAR, batch_size=1024, shuffle=True)\n",
    "\n",
    "epoch_num = 10\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(epoch_num) :\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader :\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Clear previously computed gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # then compute gradient with forward and backward passes\n",
    "        train_loss = loss_function(model(images), labels)\n",
    "        total_loss += train_loss.item()\n",
    "        train_loss.backward()\n",
    "\n",
    "        # perform SGD step (parameter update)\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: {epoch+1}/{epoch_num}, loss = {total_loss}')\n",
    "end = time.time()\n",
    "print(\"Time ellapsed in training is: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test set] Average loss: 1.5287, Accuracy: 4564/10000 (45.64%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 5: (same step)\n",
    "'''\n",
    "test_loss, correct = 0, 0\n",
    "\n",
    "# Test data\n",
    "test_loader = DataLoader(dataset=test_CIFAR, batch_size=1, shuffle=False)\n",
    "# no need to shuffle test data\n",
    "\n",
    "# Evaluate accuracy using test data\n",
    "for ind, (image, label) in enumerate(test_loader) :\n",
    "    image, label = image.to(device), label.to(device)\n",
    "    # Forward pass\n",
    "    output = model(image)\n",
    "\n",
    "    # Calculate cumulative loss\n",
    "    test_loss += loss_function(output, label).item()\n",
    "\n",
    "    # Get index of maximum log-probability\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "    # Trace correct predictions\n",
    "    correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "\n",
    "            \n",
    "# Print out the results\n",
    "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss /len(test_loader), correct, len(test_loader),\n",
    "        100. * correct / len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10: MLP4 with Softmax (10-classes)\n",
    "### Learning rate 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, loss = 29.548378467559814\n",
      "Epoch: 2/10, loss = 29.74437379837036\n",
      "Epoch: 3/10, loss = 29.285157203674316\n",
      "Epoch: 4/10, loss = 29.410550355911255\n",
      "Epoch: 5/10, loss = 29.819811820983887\n",
      "Epoch: 6/10, loss = 29.296559810638428\n",
      "Epoch: 7/10, loss = 29.344051837921143\n",
      "Epoch: 8/10, loss = 28.92134737968445\n",
      "Epoch: 9/10, loss = 29.052024126052856\n",
      "Epoch: 10/10, loss = 28.971379041671753\n",
      "Time ellapsed in training is: 44.203165769577026\n",
      "[Test set] Average loss: 2.3013, Accuracy: 1123/10000 (11.23%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "class MLP4(nn.Module) :\n",
    "    '''\n",
    "    Initialize model\n",
    "        input_dim : dimension of given input data\n",
    "    '''\n",
    "    # CIFAR-10 data is 32*32 images with 3 RGB channels\n",
    "    def __init__(self, input_dim=3*32*32) :\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, input_dim//2, bias=True)\n",
    "        self.linear2 = nn.Linear(input_dim//2, input_dim//4, bias=True)\n",
    "        self.linear3 = nn.Linear(input_dim//4, input_dim//8, bias=True)\n",
    "        self.linear4 = nn.Linear(input_dim//8, 10, bias=True)\n",
    "        \n",
    "    ''' forward given input x '''\n",
    "    def forward(self, x) :\n",
    "        x = x.float().view(-1, 3*32*32)\n",
    "        x = nn.functional.relu(self.linear(x))\n",
    "        x = nn.functional.relu(self.linear2(x))\n",
    "        x = nn.functional.relu(self.linear3(x))\n",
    "        x = self.linear4(x)\n",
    "        return x\n",
    "\n",
    "model = MLP4().to(device)                       # Define a Neural Network Model\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()     # Specify loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=5e-1)   # specify SGD with learning rate\n",
    "\n",
    "# train\n",
    "train_loader = DataLoader(dataset=train_CIFAR, batch_size=4096, shuffle=True)\n",
    "epoch_num = 10\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(epoch_num) :\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader :\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Clear previously computed gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # then compute gradient with forward and backward passes\n",
    "        train_loss = loss_function(model(images), labels)\n",
    "        total_loss += train_loss.item()\n",
    "        train_loss.backward()\n",
    "\n",
    "        # perform SGD step (parameter update)\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: {epoch+1}/{epoch_num}, loss = {total_loss}')\n",
    "end = time.time()\n",
    "print(\"Time ellapsed in training is: {}\".format(end - start))\n",
    "\n",
    "\n",
    "# test\n",
    "test_loss, correct = 0, 0\n",
    "\n",
    "# Test data\n",
    "test_loader = DataLoader(dataset=test_CIFAR, batch_size=1, shuffle=False)\n",
    "# no need to shuffle test data\n",
    "\n",
    "# Evaluate accuracy using test data\n",
    "for ind, (image, label) in enumerate(test_loader) :\n",
    "    image, label = image.to(device), label.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(image)\n",
    "\n",
    "    # Calculate cumulative loss\n",
    "    test_loss += loss_function(output, label).item()\n",
    "\n",
    "    # Get index of maximum log-probability\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "    # Trace correct predictions\n",
    "    correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "\n",
    "            \n",
    "# Print out the results\n",
    "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss /len(test_loader), correct, len(test_loader),\n",
    "        100. * correct / len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, loss = 29.843558073043823\n",
      "Epoch: 2/10, loss = 29.618691444396973\n",
      "Epoch: 3/10, loss = 29.26599144935608\n",
      "Epoch: 4/10, loss = 28.626635551452637\n",
      "Epoch: 5/10, loss = 28.370888233184814\n",
      "Epoch: 6/10, loss = 28.051732063293457\n",
      "Epoch: 7/10, loss = 27.6820330619812\n",
      "Epoch: 8/10, loss = 27.39026975631714\n",
      "Epoch: 9/10, loss = 26.976962089538574\n",
      "Epoch: 10/10, loss = 26.541860342025757\n",
      "Time ellapsed in training is: 46.26237177848816\n",
      "[Test set] Average loss: 2.0079, Accuracy: 2899/10000 (28.99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "class MLP4(nn.Module) :\n",
    "    '''\n",
    "    Initialize model\n",
    "        input_dim : dimension of given input data\n",
    "    '''\n",
    "    # CIFAR-10 data is 32*32 images with 3 RGB channels\n",
    "    def __init__(self, input_dim=3*32*32) :\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, input_dim//2, bias=True)\n",
    "        self.linear2 = nn.Linear(input_dim//2, input_dim//4, bias=True)\n",
    "        self.linear3 = nn.Linear(input_dim//4, input_dim//8, bias=True)\n",
    "        self.linear4 = nn.Linear(input_dim//8, 10, bias=True)\n",
    "        \n",
    "    ''' forward given input x '''\n",
    "    def forward(self, x) :\n",
    "        x = x.float().view(-1, 3*32*32)\n",
    "        x = nn.functional.relu(self.linear(x))\n",
    "        x = nn.functional.relu(self.linear2(x))\n",
    "        x = nn.functional.relu(self.linear3(x))\n",
    "        x = self.linear4(x)\n",
    "        return x\n",
    "\n",
    "model = MLP4().to(device)                       # Define a Neural Network Model\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()     # Specify loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)   # specify SGD with learning rate\n",
    "\n",
    "# train\n",
    "train_loader = DataLoader(dataset=train_CIFAR, batch_size=4096, shuffle=True)\n",
    "epoch_num = 10\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(epoch_num) :\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader :\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Clear previously computed gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # then compute gradient with forward and backward passes\n",
    "        train_loss = loss_function(model(images), labels)\n",
    "        total_loss += train_loss.item()\n",
    "        train_loss.backward()\n",
    "\n",
    "        # perform SGD step (parameter update)\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: {epoch+1}/{epoch_num}, loss = {total_loss}')\n",
    "end = time.time()\n",
    "print(\"Time ellapsed in training is: {}\".format(end - start))\n",
    "\n",
    "\n",
    "# test\n",
    "test_loss, correct = 0, 0\n",
    "\n",
    "# Test data\n",
    "test_loader = DataLoader(dataset=test_CIFAR, batch_size=1, shuffle=False)\n",
    "# no need to shuffle test data\n",
    "\n",
    "# Evaluate accuracy using test data\n",
    "for ind, (image, label) in enumerate(test_loader) :\n",
    "    image, label = image.to(device), label.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(image)\n",
    "\n",
    "    # Calculate cumulative loss\n",
    "    test_loss += loss_function(output, label).item()\n",
    "\n",
    "    # Get index of maximum log-probability\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "    # Trace correct predictions\n",
    "    correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "\n",
    "            \n",
    "# Print out the results\n",
    "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss /len(test_loader), correct, len(test_loader),\n",
    "        100. * correct / len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate 0.1, epoch 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, loss = 29.846237182617188\n",
      "Epoch: 2/100, loss = 29.602301836013794\n",
      "Epoch: 3/100, loss = 29.220120429992676\n",
      "Epoch: 4/100, loss = 28.521347284317017\n",
      "Epoch: 5/100, loss = 28.29578709602356\n",
      "Epoch: 6/100, loss = 27.986599922180176\n",
      "Epoch: 7/100, loss = 27.570213556289673\n",
      "Epoch: 8/100, loss = 27.07690143585205\n",
      "Epoch: 9/100, loss = 27.02597403526306\n",
      "Epoch: 10/100, loss = 26.447596073150635\n",
      "Epoch: 11/100, loss = 26.506394743919373\n",
      "Epoch: 12/100, loss = 26.160455226898193\n",
      "Epoch: 13/100, loss = 26.246181845664978\n",
      "Epoch: 14/100, loss = 25.834636092185974\n",
      "Epoch: 15/100, loss = 25.49835455417633\n",
      "Epoch: 16/100, loss = 25.770874977111816\n",
      "Epoch: 17/100, loss = 25.171059727668762\n",
      "Epoch: 18/100, loss = 25.27652657032013\n",
      "Epoch: 19/100, loss = 25.005683660507202\n",
      "Epoch: 20/100, loss = 24.892633199691772\n",
      "Epoch: 21/100, loss = 24.651652216911316\n",
      "Epoch: 22/100, loss = 24.733332633972168\n",
      "Epoch: 23/100, loss = 24.325074791908264\n",
      "Epoch: 24/100, loss = 24.432835817337036\n",
      "Epoch: 25/100, loss = 24.20593297481537\n",
      "Epoch: 26/100, loss = 24.151100158691406\n",
      "Epoch: 27/100, loss = 24.105786681175232\n",
      "Epoch: 28/100, loss = 23.770771384239197\n",
      "Epoch: 29/100, loss = 23.790993213653564\n",
      "Epoch: 30/100, loss = 24.012837052345276\n",
      "Epoch: 31/100, loss = 23.430684089660645\n",
      "Epoch: 32/100, loss = 23.58421528339386\n",
      "Epoch: 33/100, loss = 23.3797390460968\n",
      "Epoch: 34/100, loss = 23.565353870391846\n",
      "Epoch: 35/100, loss = 23.367358207702637\n",
      "Epoch: 36/100, loss = 23.320908784866333\n",
      "Epoch: 37/100, loss = 23.09727370738983\n",
      "Epoch: 38/100, loss = 23.064934134483337\n",
      "Epoch: 39/100, loss = 23.00425899028778\n",
      "Epoch: 40/100, loss = 22.990220427513123\n",
      "Epoch: 41/100, loss = 22.788782119750977\n",
      "Epoch: 42/100, loss = 22.79431676864624\n",
      "Epoch: 43/100, loss = 22.448811888694763\n",
      "Epoch: 44/100, loss = 22.993831634521484\n",
      "Epoch: 45/100, loss = 22.654130339622498\n",
      "Epoch: 46/100, loss = 22.684356927871704\n",
      "Epoch: 47/100, loss = 22.36667561531067\n",
      "Epoch: 48/100, loss = 22.594147443771362\n",
      "Epoch: 49/100, loss = 22.11765170097351\n",
      "Epoch: 50/100, loss = 22.316110849380493\n",
      "Epoch: 51/100, loss = 22.530731320381165\n",
      "Epoch: 52/100, loss = 22.14802575111389\n",
      "Epoch: 53/100, loss = 22.138954520225525\n",
      "Epoch: 54/100, loss = 22.19292962551117\n",
      "Epoch: 55/100, loss = 22.051324486732483\n",
      "Epoch: 56/100, loss = 22.152352809906006\n",
      "Epoch: 57/100, loss = 22.11206614971161\n",
      "Epoch: 58/100, loss = 21.722447633743286\n",
      "Epoch: 59/100, loss = 21.828033924102783\n",
      "Epoch: 60/100, loss = 22.073859214782715\n",
      "Epoch: 61/100, loss = 21.80317223072052\n",
      "Epoch: 62/100, loss = 21.995595693588257\n",
      "Epoch: 63/100, loss = 21.739506006240845\n",
      "Epoch: 64/100, loss = 21.581972002983093\n",
      "Epoch: 65/100, loss = 21.48181128501892\n",
      "Epoch: 66/100, loss = 21.68856632709503\n",
      "Epoch: 67/100, loss = 21.51231598854065\n",
      "Epoch: 68/100, loss = 21.465447425842285\n",
      "Epoch: 69/100, loss = 21.233358144760132\n",
      "Epoch: 70/100, loss = 21.311264276504517\n",
      "Epoch: 71/100, loss = 21.313618302345276\n",
      "Epoch: 72/100, loss = 21.304230213165283\n",
      "Epoch: 73/100, loss = 20.977646470069885\n",
      "Epoch: 74/100, loss = 21.50716471672058\n",
      "Epoch: 75/100, loss = 21.05112135410309\n",
      "Epoch: 76/100, loss = 21.111785650253296\n",
      "Epoch: 77/100, loss = 21.073532700538635\n",
      "Epoch: 78/100, loss = 20.712255597114563\n",
      "Epoch: 79/100, loss = 20.862988352775574\n",
      "Epoch: 80/100, loss = 21.355875968933105\n",
      "Epoch: 81/100, loss = 21.049999237060547\n",
      "Epoch: 82/100, loss = 20.742987155914307\n",
      "Epoch: 83/100, loss = 20.608863353729248\n",
      "Epoch: 84/100, loss = 20.739519000053406\n",
      "Epoch: 85/100, loss = 20.67194104194641\n",
      "Epoch: 86/100, loss = 20.475537657737732\n",
      "Epoch: 87/100, loss = 20.628116726875305\n",
      "Epoch: 88/100, loss = 20.68820834159851\n",
      "Epoch: 89/100, loss = 20.594582438468933\n",
      "Epoch: 90/100, loss = 20.70904052257538\n",
      "Epoch: 91/100, loss = 20.436856269836426\n",
      "Epoch: 92/100, loss = 20.563469290733337\n",
      "Epoch: 93/100, loss = 20.43774139881134\n",
      "Epoch: 94/100, loss = 20.265443801879883\n",
      "Epoch: 95/100, loss = 20.502374529838562\n",
      "Epoch: 96/100, loss = 20.49900186061859\n",
      "Epoch: 97/100, loss = 20.447824001312256\n",
      "Epoch: 98/100, loss = 19.954501271247864\n",
      "Epoch: 99/100, loss = 20.126807928085327\n",
      "Epoch: 100/100, loss = 19.94218349456787\n",
      "Time ellapsed in training is: 452.88041043281555\n",
      "[Test set] Average loss: 1.6859, Accuracy: 4029/10000 (40.29%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "class MLP4(nn.Module) :\n",
    "    '''\n",
    "    Initialize model\n",
    "        input_dim : dimension of given input data\n",
    "    '''\n",
    "    # CIFAR-10 data is 32*32 images with 3 RGB channels\n",
    "    def __init__(self, input_dim=3*32*32) :\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, input_dim//2, bias=True)\n",
    "        self.linear2 = nn.Linear(input_dim//2, input_dim//4, bias=True)\n",
    "        self.linear3 = nn.Linear(input_dim//4, input_dim//8, bias=True)\n",
    "        self.linear4 = nn.Linear(input_dim//8, 10, bias=True)\n",
    "        \n",
    "    ''' forward given input x '''\n",
    "    def forward(self, x) :\n",
    "        x = x.float().view(-1, 3*32*32)\n",
    "        x = nn.functional.relu(self.linear(x))\n",
    "        x = nn.functional.relu(self.linear2(x))\n",
    "        x = nn.functional.relu(self.linear3(x))\n",
    "        x = self.linear4(x)\n",
    "        return x\n",
    "\n",
    "model = MLP4().to(device)                       # Define a Neural Network Model\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()     # Specify loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)   # specify SGD with learning rate\n",
    "\n",
    "# train\n",
    "train_loader = DataLoader(dataset=train_CIFAR, batch_size=4096, shuffle=True)\n",
    "epoch_num = 100\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(epoch_num) :\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader :\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Clear previously computed gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # then compute gradient with forward and backward passes\n",
    "        train_loss = loss_function(model(images), labels)\n",
    "        total_loss += train_loss.item()\n",
    "        train_loss.backward()\n",
    "\n",
    "        # perform SGD step (parameter update)\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: {epoch+1}/{epoch_num}, loss = {total_loss}')\n",
    "end = time.time()\n",
    "print(\"Time ellapsed in training is: {}\".format(end - start))\n",
    "\n",
    "\n",
    "# test\n",
    "test_loss, correct = 0, 0\n",
    "\n",
    "# Test data\n",
    "test_loader = DataLoader(dataset=test_CIFAR, batch_size=1, shuffle=False)\n",
    "# no need to shuffle test data\n",
    "\n",
    "# Evaluate accuracy using test data\n",
    "for ind, (image, label) in enumerate(test_loader) :\n",
    "    image, label = image.to(device), label.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(image)\n",
    "\n",
    "    # Calculate cumulative loss\n",
    "    test_loss += loss_function(output, label).item()\n",
    "\n",
    "    # Get index of maximum log-probability\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "    # Trace correct predictions\n",
    "    correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "\n",
    "            \n",
    "# Print out the results\n",
    "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss /len(test_loader), correct, len(test_loader),\n",
    "        100. * correct / len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate 0.05, epoch=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, loss = 29.845097064971924\n",
      "Epoch: 2/100, loss = 29.615514516830444\n",
      "Epoch: 3/100, loss = 29.21963596343994\n",
      "Epoch: 4/100, loss = 28.49018669128418\n",
      "Epoch: 5/100, loss = 28.312822580337524\n",
      "Epoch: 6/100, loss = 27.964833974838257\n",
      "Epoch: 7/100, loss = 27.52726936340332\n",
      "Epoch: 8/100, loss = 27.464649438858032\n",
      "Epoch: 9/100, loss = 26.85899782180786\n",
      "Epoch: 10/100, loss = 26.40575611591339\n",
      "Epoch: 11/100, loss = 26.50705087184906\n",
      "Epoch: 12/100, loss = 26.27977466583252\n",
      "Epoch: 13/100, loss = 25.91855764389038\n",
      "Epoch: 14/100, loss = 25.854105234146118\n",
      "Epoch: 15/100, loss = 25.657342553138733\n",
      "Epoch: 16/100, loss = 25.469631552696228\n",
      "Epoch: 17/100, loss = 25.39148509502411\n",
      "Epoch: 18/100, loss = 25.00677800178528\n",
      "Epoch: 19/100, loss = 25.121166348457336\n",
      "Epoch: 20/100, loss = 24.731921434402466\n",
      "Epoch: 21/100, loss = 24.566386580467224\n",
      "Epoch: 22/100, loss = 24.65404236316681\n",
      "Epoch: 23/100, loss = 24.439467072486877\n",
      "Epoch: 24/100, loss = 24.27803635597229\n",
      "Epoch: 25/100, loss = 24.177013397216797\n",
      "Epoch: 26/100, loss = 24.282001733779907\n",
      "Epoch: 27/100, loss = 23.898887634277344\n",
      "Epoch: 28/100, loss = 23.85926878452301\n",
      "Epoch: 29/100, loss = 23.892826914787292\n",
      "Epoch: 30/100, loss = 23.753647089004517\n",
      "Epoch: 31/100, loss = 23.67233419418335\n",
      "Epoch: 32/100, loss = 23.506554007530212\n",
      "Epoch: 33/100, loss = 23.56555211544037\n",
      "Epoch: 34/100, loss = 23.33491349220276\n",
      "Epoch: 35/100, loss = 23.24964928627014\n",
      "Epoch: 36/100, loss = 23.457464814186096\n",
      "Epoch: 37/100, loss = 23.17814028263092\n",
      "Epoch: 38/100, loss = 22.989736437797546\n",
      "Epoch: 39/100, loss = 23.199016332626343\n",
      "Epoch: 40/100, loss = 22.961812019348145\n",
      "Epoch: 41/100, loss = 22.69402587413788\n",
      "Epoch: 42/100, loss = 23.160424828529358\n",
      "Epoch: 43/100, loss = 22.666409373283386\n",
      "Epoch: 44/100, loss = 22.651228189468384\n",
      "Epoch: 45/100, loss = 22.79314398765564\n",
      "Epoch: 46/100, loss = 22.494127869606018\n",
      "Epoch: 47/100, loss = 22.531315207481384\n",
      "Epoch: 48/100, loss = 22.458449959754944\n",
      "Epoch: 49/100, loss = 22.294013619422913\n",
      "Epoch: 50/100, loss = 22.494970560073853\n",
      "Epoch: 51/100, loss = 22.139172792434692\n",
      "Epoch: 52/100, loss = 22.048961520195007\n",
      "Epoch: 53/100, loss = 22.384241342544556\n",
      "Epoch: 54/100, loss = 21.921392917633057\n",
      "Epoch: 55/100, loss = 21.943007946014404\n",
      "Epoch: 56/100, loss = 22.228999257087708\n",
      "Epoch: 57/100, loss = 21.983853220939636\n",
      "Epoch: 58/100, loss = 21.995237946510315\n",
      "Epoch: 59/100, loss = 22.1153781414032\n",
      "Epoch: 60/100, loss = 21.748595476150513\n",
      "Epoch: 61/100, loss = 21.796419978141785\n",
      "Epoch: 62/100, loss = 21.768916964530945\n",
      "Epoch: 63/100, loss = 21.608180165290833\n",
      "Epoch: 64/100, loss = 21.70727026462555\n",
      "Epoch: 65/100, loss = 21.396053433418274\n",
      "Epoch: 66/100, loss = 21.814443945884705\n",
      "Epoch: 67/100, loss = 21.55015277862549\n",
      "Epoch: 68/100, loss = 21.48857808113098\n",
      "Epoch: 69/100, loss = 21.367921590805054\n",
      "Epoch: 70/100, loss = 21.180128574371338\n",
      "Epoch: 71/100, loss = 21.667927980422974\n",
      "Epoch: 72/100, loss = 21.264281272888184\n",
      "Epoch: 73/100, loss = 21.249285578727722\n",
      "Epoch: 74/100, loss = 21.373252868652344\n",
      "Epoch: 75/100, loss = 20.938187956809998\n",
      "Epoch: 76/100, loss = 21.336326122283936\n",
      "Epoch: 77/100, loss = 21.150819659233093\n",
      "Epoch: 78/100, loss = 20.8099102973938\n",
      "Epoch: 79/100, loss = 20.929805040359497\n",
      "Epoch: 80/100, loss = 20.730301022529602\n",
      "Epoch: 81/100, loss = 20.84882915019989\n",
      "Epoch: 82/100, loss = 20.920133352279663\n",
      "Epoch: 83/100, loss = 20.8688223361969\n",
      "Epoch: 84/100, loss = 20.716428637504578\n",
      "Epoch: 85/100, loss = 20.804456114768982\n",
      "Epoch: 86/100, loss = 20.404581904411316\n",
      "Epoch: 87/100, loss = 20.57843852043152\n",
      "Epoch: 88/100, loss = 20.52667725086212\n",
      "Epoch: 89/100, loss = 20.702980399131775\n",
      "Epoch: 90/100, loss = 20.507997632026672\n",
      "Epoch: 91/100, loss = 20.468607544898987\n",
      "Epoch: 92/100, loss = 20.375937461853027\n",
      "Epoch: 93/100, loss = 20.624131679534912\n",
      "Epoch: 94/100, loss = 20.410698771476746\n",
      "Epoch: 95/100, loss = 20.06947159767151\n",
      "Epoch: 96/100, loss = 20.28368580341339\n",
      "Epoch: 97/100, loss = 20.058900475502014\n",
      "Epoch: 98/100, loss = 20.28917419910431\n",
      "Epoch: 99/100, loss = 20.72190570831299\n",
      "Epoch: 100/100, loss = 20.07922351360321\n",
      "Time ellapsed in training is: 451.2125949859619\n",
      "[Test set] Average loss: 1.6121, Accuracy: 4229/10000 (42.29%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "class MLP4(nn.Module) :\n",
    "    '''\n",
    "    Initialize model\n",
    "        input_dim : dimension of given input data\n",
    "    '''\n",
    "    # CIFAR-10 data is 32*32 images with 3 RGB channels\n",
    "    def __init__(self, input_dim=3*32*32) :\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, input_dim//2, bias=True)\n",
    "        self.linear2 = nn.Linear(input_dim//2, input_dim//4, bias=True)\n",
    "        self.linear3 = nn.Linear(input_dim//4, input_dim//8, bias=True)\n",
    "        self.linear4 = nn.Linear(input_dim//8, 10, bias=True)\n",
    "        \n",
    "    ''' forward given input x '''\n",
    "    def forward(self, x) :\n",
    "        x = x.float().view(-1, 3*32*32)\n",
    "        x = nn.functional.relu(self.linear(x))\n",
    "        x = nn.functional.relu(self.linear2(x))\n",
    "        x = nn.functional.relu(self.linear3(x))\n",
    "        x = self.linear4(x)\n",
    "        return x\n",
    "\n",
    "model = MLP4().to(device)                       # Define a Neural Network Model\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()     # Specify loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)   # specify SGD with learning rate\n",
    "\n",
    "# train\n",
    "train_loader = DataLoader(dataset=train_CIFAR, batch_size=4096, shuffle=True)\n",
    "epoch_num = 100\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(epoch_num) :\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader :\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Clear previously computed gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # then compute gradient with forward and backward passes\n",
    "        train_loss = loss_function(model(images), labels)\n",
    "        total_loss += train_loss.item()\n",
    "        train_loss.backward()\n",
    "\n",
    "        # perform SGD step (parameter update)\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: {epoch+1}/{epoch_num}, loss = {total_loss}')\n",
    "end = time.time()\n",
    "print(\"Time ellapsed in training is: {}\".format(end - start))\n",
    "\n",
    "\n",
    "# test\n",
    "test_loss, correct = 0, 0\n",
    "\n",
    "# Test data\n",
    "test_loader = DataLoader(dataset=test_CIFAR, batch_size=1, shuffle=False)\n",
    "# no need to shuffle test data\n",
    "\n",
    "# Evaluate accuracy using test data\n",
    "for ind, (image, label) in enumerate(test_loader) :\n",
    "    image, label = image.to(device), label.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(image)\n",
    "\n",
    "    # Calculate cumulative loss\n",
    "    test_loss += loss_function(output, label).item()\n",
    "\n",
    "    # Get index of maximum log-probability\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "    # Trace correct predictions\n",
    "    correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "\n",
    "            \n",
    "# Print out the results\n",
    "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss /len(test_loader), correct, len(test_loader),\n",
    "        100. * correct / len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
