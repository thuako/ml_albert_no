{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modern LeNet5 on CIFAR10 with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar_10data/cifar-10-python.tar.gz\n",
      "Extracting ./cifar_10data/cifar-10-python.tar.gz to ./cifar_10data/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2825e8fe98748a1810a30fb1206d601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
     },
     "metadata": {
      "transient": {}
     },
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-29844394871d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mStep\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m '''\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "'''\n",
    "Step 1\n",
    "'''\n",
    "\n",
    "# Image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./cifar_10data/',\n",
    "                                 train=True, \n",
    "                                 transform=transform,\n",
    "                                 download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='./cifar_10data/',\n",
    "                                train=False, \n",
    "                                transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "Step 2\n",
    "'''\n",
    "class LeNet(nn.Module) :\n",
    "    \n",
    "    def __init__(self) :\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "                nn.Conv2d(3, 6, kernel_size=5),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "        self.pool_layer1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "                nn.Conv2d(6, 16, kernel_size=5),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "        self.pool_layer2 = nn.MaxPool2d(kernel_size=2, stride=2)  \n",
    "        self.C5_layer = nn.Sequential(\n",
    "                nn.Linear(5*5*16, 120),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "        self.fc_layer1 = nn.Sequential(\n",
    "                nn.Linear(120, 84),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "        self.fc_layer2 = nn.Linear(84, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x) :\n",
    "        output = self.conv_layer1(x)\n",
    "        output = self.pool_layer1(output)\n",
    "        output = self.conv_layer2(output)\n",
    "        output = self.pool_layer2(output)\n",
    "        output = output.view(-1,5*5*16)\n",
    "        output = self.C5_layer(output)\n",
    "        output = self.fc_layer1(output)\n",
    "        output = self.fc_layer2(output)\n",
    "        return output\n",
    "\n",
    "    \n",
    "'''\n",
    "Step 3\n",
    "'''\n",
    "model = LeNet().to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "'''\n",
    "Step 4\n",
    "'''\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(200) :\n",
    "    print(\"{}th epoch starting.\".format(epoch))\n",
    "    for images, labels in train_loader :\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss = loss_function(model(images), labels)\n",
    "        train_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "end = time.time()\n",
    "print(\"Time ellapsed in training is: {}\".format(end - start))\n",
    "\n",
    "\n",
    "'''\n",
    "Step 5\n",
    "'''\n",
    "test_loss, correct, total = 0, 0, 0\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "for images, labels in test_loader :\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    output = model(images)\n",
    "    test_loss += loss_function(output, labels).item()\n",
    "\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    \n",
    "    total += labels.size(0)\n",
    "            \n",
    "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss /total, correct, total,\n",
    "        100. * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout + modern LeNet5 + data augmentation\n",
    "\n",
    "Results: [Test set] Average loss: 0.0091, Accuracy: 6817/10000 (68.17%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "0th epoch starting.\n",
      "1th epoch starting.\n",
      "2th epoch starting.\n",
      "3th epoch starting.\n",
      "4th epoch starting.\n",
      "5th epoch starting.\n",
      "6th epoch starting.\n",
      "7th epoch starting.\n",
      "8th epoch starting.\n",
      "9th epoch starting.\n",
      "10th epoch starting.\n",
      "11th epoch starting.\n",
      "12th epoch starting.\n",
      "13th epoch starting.\n",
      "14th epoch starting.\n",
      "15th epoch starting.\n",
      "16th epoch starting.\n",
      "17th epoch starting.\n",
      "18th epoch starting.\n",
      "19th epoch starting.\n",
      "20th epoch starting.\n",
      "21th epoch starting.\n",
      "22th epoch starting.\n",
      "23th epoch starting.\n",
      "24th epoch starting.\n",
      "25th epoch starting.\n",
      "26th epoch starting.\n",
      "27th epoch starting.\n",
      "28th epoch starting.\n",
      "29th epoch starting.\n",
      "30th epoch starting.\n",
      "31th epoch starting.\n",
      "32th epoch starting.\n",
      "33th epoch starting.\n",
      "34th epoch starting.\n",
      "35th epoch starting.\n",
      "36th epoch starting.\n",
      "37th epoch starting.\n",
      "38th epoch starting.\n",
      "39th epoch starting.\n",
      "40th epoch starting.\n",
      "41th epoch starting.\n",
      "42th epoch starting.\n",
      "43th epoch starting.\n",
      "44th epoch starting.\n",
      "45th epoch starting.\n",
      "46th epoch starting.\n",
      "47th epoch starting.\n",
      "48th epoch starting.\n",
      "49th epoch starting.\n",
      "50th epoch starting.\n",
      "51th epoch starting.\n",
      "52th epoch starting.\n",
      "53th epoch starting.\n",
      "54th epoch starting.\n",
      "55th epoch starting.\n",
      "56th epoch starting.\n",
      "57th epoch starting.\n",
      "58th epoch starting.\n",
      "59th epoch starting.\n",
      "60th epoch starting.\n",
      "61th epoch starting.\n",
      "62th epoch starting.\n",
      "63th epoch starting.\n",
      "64th epoch starting.\n",
      "65th epoch starting.\n",
      "66th epoch starting.\n",
      "67th epoch starting.\n",
      "68th epoch starting.\n",
      "69th epoch starting.\n",
      "70th epoch starting.\n",
      "71th epoch starting.\n",
      "72th epoch starting.\n",
      "73th epoch starting.\n",
      "74th epoch starting.\n",
      "75th epoch starting.\n",
      "76th epoch starting.\n",
      "77th epoch starting.\n",
      "78th epoch starting.\n",
      "79th epoch starting.\n",
      "80th epoch starting.\n",
      "81th epoch starting.\n",
      "82th epoch starting.\n",
      "83th epoch starting.\n",
      "84th epoch starting.\n",
      "85th epoch starting.\n",
      "86th epoch starting.\n",
      "87th epoch starting.\n",
      "88th epoch starting.\n",
      "89th epoch starting.\n",
      "90th epoch starting.\n",
      "91th epoch starting.\n",
      "92th epoch starting.\n",
      "93th epoch starting.\n",
      "94th epoch starting.\n",
      "95th epoch starting.\n",
      "96th epoch starting.\n",
      "97th epoch starting.\n",
      "98th epoch starting.\n",
      "99th epoch starting.\n",
      "100th epoch starting.\n",
      "101th epoch starting.\n",
      "102th epoch starting.\n",
      "103th epoch starting.\n",
      "104th epoch starting.\n",
      "105th epoch starting.\n",
      "106th epoch starting.\n",
      "107th epoch starting.\n",
      "108th epoch starting.\n",
      "109th epoch starting.\n",
      "110th epoch starting.\n",
      "111th epoch starting.\n",
      "112th epoch starting.\n",
      "113th epoch starting.\n",
      "114th epoch starting.\n",
      "115th epoch starting.\n",
      "116th epoch starting.\n",
      "117th epoch starting.\n",
      "118th epoch starting.\n",
      "119th epoch starting.\n",
      "120th epoch starting.\n",
      "121th epoch starting.\n",
      "122th epoch starting.\n",
      "123th epoch starting.\n",
      "124th epoch starting.\n",
      "125th epoch starting.\n",
      "126th epoch starting.\n",
      "127th epoch starting.\n",
      "128th epoch starting.\n",
      "129th epoch starting.\n",
      "130th epoch starting.\n",
      "131th epoch starting.\n",
      "132th epoch starting.\n",
      "133th epoch starting.\n",
      "134th epoch starting.\n",
      "135th epoch starting.\n",
      "136th epoch starting.\n",
      "137th epoch starting.\n",
      "138th epoch starting.\n",
      "139th epoch starting.\n",
      "140th epoch starting.\n",
      "141th epoch starting.\n",
      "142th epoch starting.\n",
      "143th epoch starting.\n",
      "144th epoch starting.\n",
      "145th epoch starting.\n",
      "146th epoch starting.\n",
      "147th epoch starting.\n",
      "148th epoch starting.\n",
      "149th epoch starting.\n",
      "150th epoch starting.\n",
      "151th epoch starting.\n",
      "152th epoch starting.\n",
      "153th epoch starting.\n",
      "154th epoch starting.\n",
      "155th epoch starting.\n",
      "156th epoch starting.\n",
      "157th epoch starting.\n",
      "158th epoch starting.\n",
      "159th epoch starting.\n",
      "160th epoch starting.\n",
      "161th epoch starting.\n",
      "162th epoch starting.\n",
      "163th epoch starting.\n",
      "164th epoch starting.\n",
      "165th epoch starting.\n",
      "166th epoch starting.\n",
      "167th epoch starting.\n",
      "168th epoch starting.\n",
      "169th epoch starting.\n",
      "170th epoch starting.\n",
      "171th epoch starting.\n",
      "172th epoch starting.\n",
      "173th epoch starting.\n",
      "174th epoch starting.\n",
      "175th epoch starting.\n",
      "176th epoch starting.\n",
      "177th epoch starting.\n",
      "178th epoch starting.\n",
      "179th epoch starting.\n",
      "180th epoch starting.\n",
      "181th epoch starting.\n",
      "182th epoch starting.\n",
      "183th epoch starting.\n",
      "184th epoch starting.\n",
      "185th epoch starting.\n",
      "186th epoch starting.\n",
      "187th epoch starting.\n",
      "188th epoch starting.\n",
      "189th epoch starting.\n",
      "190th epoch starting.\n",
      "191th epoch starting.\n",
      "192th epoch starting.\n",
      "193th epoch starting.\n",
      "194th epoch starting.\n",
      "195th epoch starting.\n",
      "196th epoch starting.\n",
      "197th epoch starting.\n",
      "198th epoch starting.\n",
      "199th epoch starting.\n",
      "Time ellapsed in training is: 3046.977497816086\n",
      "[Test set] Average loss: 0.0093, Accuracy: 6732/10000 (67.32%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "'''\n",
    "Step 1:\n",
    "'''\n",
    "\n",
    "# Image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./cifar_10data/',\n",
    "                                 train=True, \n",
    "                                 transform=transform,\n",
    "                                 download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='./cifar_10data/',\n",
    "                                train=False, \n",
    "                                transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "Step 2\n",
    "'''\n",
    "class LeNet(nn.Module) :\n",
    "\n",
    "    def __init__(self) :\n",
    "        super(LeNet, self).__init__()\n",
    "        p_drop = 0.1\n",
    "        \n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "                nn.Conv2d(3, 6, kernel_size=5),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "        self.pool_layer1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "                nn.Conv2d(6, 16, kernel_size=5),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "        self.pool_layer2 = nn.MaxPool2d(kernel_size=2, stride=2)  \n",
    "        self.C5_layer = nn.Sequential(\n",
    "                nn.Linear(5*5*16, 120),\n",
    "                nn.Dropout(p=p_drop),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "        self.fc_layer1 = nn.Sequential(\n",
    "                nn.Linear(120, 84),\n",
    "                nn.Dropout(p=p_drop),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "        self.fc_layer2 = nn.Linear(84, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x) :\n",
    "        output = self.conv_layer1(x)\n",
    "        output = self.pool_layer1(output)\n",
    "        output = self.conv_layer2(output)\n",
    "        output = self.pool_layer2(output)\n",
    "        output = output.view(-1,5*5*16)\n",
    "        output = self.C5_layer(output)\n",
    "        output = self.fc_layer1(output)\n",
    "        output = self.fc_layer2(output)\n",
    "        return output\n",
    "\n",
    "'''\n",
    "Step 3\n",
    "'''\n",
    "model = LeNet().to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "'''\n",
    "Step 4\n",
    "'''\n",
    "model.train()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(200) :\n",
    "    print(\"{}th epoch starting.\".format(epoch))\n",
    "    for i, (images, labels) in enumerate(train_loader) :\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss = loss_function(model(images), labels)\n",
    "        train_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time ellapsed in training is: {}\".format(end - start))\n",
    "\n",
    "\n",
    "'''\n",
    "Step 5\n",
    "'''\n",
    "model.eval()\n",
    "test_loss, correct, total = 0, 0, 0\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "for images, labels in test_loader :\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    output = model(images)\n",
    "    test_loss += loss_function(output, labels).item()\n",
    "\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "    total += labels.size(0)\n",
    "\n",
    "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss /total, correct, total,\n",
    "        100. * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight decay + modern LeNet5 + data augmentation\n",
    "\n",
    "Result: [Test set] Average loss: 0.0084, Accuracy: 7041/10000 (70.41%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "'''\n",
    "Step 1:\n",
    "'''\n",
    "\n",
    "# Image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./cifar_10data/',\n",
    "                                 train=True, \n",
    "                                 transform=transform,\n",
    "                                 download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='./cifar_10data/',\n",
    "                                train=False, \n",
    "                                transform=transforms.ToTensor())\n",
    "    \n",
    "'''\n",
    "Step 2\n",
    "'''\n",
    "class LeNet(nn.Module) :\n",
    "\n",
    "    def __init__(self) :\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "                nn.Conv2d(3, 6, kernel_size=5),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "        self.pool_layer1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "                nn.Conv2d(6, 16, kernel_size=5),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "        self.pool_layer2 = nn.MaxPool2d(kernel_size=2, stride=2)  \n",
    "        self.C5_layer = nn.Sequential(\n",
    "                nn.Linear(5*5*16, 120),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "        self.fc_layer1 = nn.Sequential(\n",
    "                nn.Linear(120, 84),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "        self.fc_layer2 = nn.Linear(84, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x) :\n",
    "        output = self.conv_layer1(x)\n",
    "        output = self.pool_layer1(output)\n",
    "        output = self.conv_layer2(output)\n",
    "        output = self.pool_layer2(output)\n",
    "        output = output.view(-1,5*5*16)\n",
    "        output = self.C5_layer(output)\n",
    "        output = self.fc_layer1(output)\n",
    "        output = self.fc_layer2(output)\n",
    "        return output\n",
    "\n",
    "'''\n",
    "Step 3\n",
    "'''\n",
    "model = LeNet().to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-05)\n",
    "\n",
    "'''\n",
    "Step 4\n",
    "'''\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(200) :\n",
    "    print(\"{}th epoch starting.\".format(epoch))\n",
    "    for i, (images, labels) in enumerate(train_loader) :\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss = loss_function(model(images), labels)\n",
    "        train_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time ellapsed in training is: {}\".format(end - start))\n",
    "\n",
    "\n",
    "'''\n",
    "Step 5\n",
    "'''\n",
    "test_loss, correct, total = 0, 0, 0\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "for images, labels in test_loader :\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    output = model(images)\n",
    "    test_loss += loss_function(output, labels).item()\n",
    "\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "    total += labels.size(0)\n",
    "\n",
    "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss /total, correct, total,\n",
    "        100. * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight decay + dropout + modern LeNet5 + data augmentation\n",
    "\n",
    "Results: [Test set] Average loss: 0.0090, Accuracy: 6893/10000 (68.93%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "'''\n",
    "Step 1:\n",
    "'''\n",
    "\n",
    "# Image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./cifar_10data/',\n",
    "                                 train=True, \n",
    "                                 transform=transform,\n",
    "                                 download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='./cifar_10data/',\n",
    "                                train=False, \n",
    "                                transform=transforms.ToTensor())\n",
    "    \n",
    "\n",
    "\n",
    "'''\n",
    "Step 2\n",
    "'''\n",
    "class LeNet(nn.Module) :\n",
    "\n",
    "    def __init__(self) :\n",
    "        super(LeNet, self).__init__()\n",
    "        p_drop = 0.5\n",
    "        \n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "                nn.Conv2d(3, 6, kernel_size=5),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "        self.pool_layer1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "                nn.Conv2d(6, 16, kernel_size=5),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "        self.pool_layer2 = nn.MaxPool2d(kernel_size=2, stride=2)  \n",
    "        self.C5_layer = nn.Sequential(\n",
    "                nn.Linear(5*5*16, 120),\n",
    "                nn.Dropout(p=p_drop),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "        self.fc_layer1 = nn.Sequential(\n",
    "                nn.Linear(120, 84),\n",
    "                nn.Dropout(p=p_drop),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "        self.fc_layer2 = nn.Linear(84, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x) :\n",
    "        output = self.conv_layer1(x)\n",
    "        output = self.pool_layer1(output)\n",
    "        output = self.conv_layer2(output)\n",
    "        output = self.pool_layer2(output)\n",
    "        output = output.view(-1,5*5*16)\n",
    "        output = self.C5_layer(output)\n",
    "        output = self.fc_layer1(output)\n",
    "        output = self.fc_layer2(output)\n",
    "        return output\n",
    "\n",
    "'''\n",
    "Step 3\n",
    "'''\n",
    "model = LeNet().to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-05)\n",
    "\n",
    "'''\n",
    "Step 4\n",
    "'''\n",
    "model.train()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(200) :\n",
    "    print(\"{}th epoch starting.\".format(epoch))\n",
    "    for i, (images, labels) in enumerate(train_loader) :\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss = loss_function(model(images), labels)\n",
    "        train_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time ellapsed in training is: {}\".format(end - start))\n",
    "\n",
    "\n",
    "'''\n",
    "Step 5\n",
    "'''\n",
    "model.eval()\n",
    "test_loss, correct, total = 0, 0, 0\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "for images, labels in test_loader :\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    output = model(images)\n",
    "    test_loss += loss_function(output, labels).item()\n",
    "\n",
    "    pred = output.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "    total += labels.size(0)\n",
    "\n",
    "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss /total, correct, total,\n",
    "        100. * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}